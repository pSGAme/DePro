================Parameters Settings=================
Parameters:	Namespace(vptNumTokens=4, text='DCoOp', textNumTokens=1, VL_independent=True, generator_layer=0, domain_specific_trick=False, decouple=False, triplet=False, ln_trick=False, log_name='baseline', disable_first_pre_ln=False, second_init='xavier', first_init='xavier', optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro_SIGIR', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 60
================Baseline Settings=================
visual UDP numbers = 4
text prompt-setup = DCoOp
text UDP numbers= 1
UDPs independent? = True
use triplet loss? = False
generator_layer_num = 0
==================================================
======== Training Parameters ========
text_prompt_learner.ctx
text_encoder.text_projection
visual_udp_generator.prompt_embeddings
visual_encoder.class_embedding
visual_encoder.proj
visual_encoder.prompt_embeddings
tot=125987072, train = 662784
===============================================
[Train] Epoch: [1/1][100/3536]  Time 0.335 (0.351)  cls 2.5125 (3.8007)  triplet 0.0765 (0.0925)  mse 0.0033 (0.0029)  tot 2.5125 (3.8007)  
[Train] Epoch: [1/1][200/3536]  Time 0.336 (0.344)  cls 2.8957 (3.2240)  triplet 0.1061 (0.0906)  mse 0.0032 (0.0031)  tot 2.8957 (3.2240)  
[Train] Epoch: [1/1][300/3536]  Time 0.336 (0.341)  cls 2.3768 (2.9674)  triplet 0.1060 (0.0928)  mse 0.0032 (0.0031)  tot 2.3768 (2.9674)  
[Train] Epoch: [1/1][400/3536]  Time 0.337 (0.340)  cls 2.4926 (2.8247)  triplet 0.1168 (0.0931)  mse 0.0032 (0.0031)  tot 2.4926 (2.8247)  
[Train] Epoch: [1/1][500/3536]  Time 1.039 (0.431)  cls 2.1771 (2.7221)  triplet 0.0331 (0.0906)  mse 0.0032 (0.0031)  tot 2.1771 (2.7221)  
[Train] Epoch: [1/1][600/3536]  Time 0.333 (0.500)  cls 2.0667 (2.6456)  triplet 0.0619 (0.0907)  mse 0.0032 (0.0032)  tot 2.0667 (2.6456)  
[Train] Epoch: [1/1][700/3536]  Time 2.461 (0.555)  cls 2.0499 (2.5832)  triplet 0.1297 (0.0908)  mse 0.0031 (0.0032)  tot 2.0499 (2.5832)  
[Train] Epoch: [1/1][800/3536]  Time 0.335 (0.586)  cls 2.1537 (2.5323)  triplet 0.0635 (0.0896)  mse 0.0032 (0.0032)  tot 2.1537 (2.5323)  
[Train] Epoch: [1/1][900/3536]  Time 0.333 (0.616)  cls 2.1944 (2.4845)  triplet 0.0898 (0.0891)  mse 0.0032 (0.0032)  tot 2.1944 (2.4845)  
[Train] Epoch: [1/1][1000/3536]  Time 0.948 (0.640)  cls 2.5204 (2.4499)  triplet 0.1106 (0.0890)  mse 0.0032 (0.0032)  tot 2.5204 (2.4499)  
[Train] Epoch: [1/1][1100/3536]  Time 0.332 (0.661)  cls 1.9816 (2.4146)  triplet 0.0523 (0.0885)  mse 0.0031 (0.0032)  tot 1.9816 (2.4146)  
[Train] Epoch: [1/1][1200/3536]  Time 0.364 (0.674)  cls 2.2876 (2.3862)  triplet 0.1320 (0.0888)  mse 0.0031 (0.0032)  tot 2.2876 (2.3862)  
[Train] Epoch: [1/1][1300/3536]  Time 0.340 (0.686)  cls 2.5632 (2.3638)  triplet 0.1080 (0.0887)  mse 0.0031 (0.0032)  tot 2.5632 (2.3638)  
[Train] Epoch: [1/1][1400/3536]  Time 0.344 (0.697)  cls 2.0427 (2.3409)  triplet 0.0821 (0.0881)  mse 0.0032 (0.0032)  tot 2.0427 (2.3409)  
[Train] Epoch: [1/1][1500/3536]  Time 0.342 (0.704)  cls 2.2671 (2.3221)  triplet 0.0984 (0.0883)  mse 0.0032 (0.0032)  tot 2.2671 (2.3221)  
[Train] Epoch: [1/1][1600/3536]  Time 0.340 (0.716)  cls 1.8048 (2.3016)  triplet 0.1789 (0.0883)  mse 0.0032 (0.0032)  tot 1.8048 (2.3016)  
[Train] Epoch: [1/1][1700/3536]  Time 3.683 (0.724)  cls 2.0421 (2.2858)  triplet 0.0238 (0.0875)  mse 0.0031 (0.0032)  tot 2.0421 (2.2858)  
[Train] Epoch: [1/1][1800/3536]  Time 0.339 (0.729)  cls 1.7526 (2.2689)  triplet 0.1230 (0.0873)  mse 0.0032 (0.0032)  tot 1.7526 (2.2689)  
[Train] Epoch: [1/1][1900/3536]  Time 0.859 (0.735)  cls 1.7075 (2.2537)  triplet 0.0284 (0.0874)  mse 0.0030 (0.0032)  tot 1.7075 (2.2537)  
[Train] Epoch: [1/1][2000/3536]  Time 0.339 (0.741)  cls 1.8247 (2.2404)  triplet 0.0696 (0.0872)  mse 0.0031 (0.0032)  tot 1.8247 (2.2404)  
[Train] Epoch: [1/1][2100/3536]  Time 0.338 (0.745)  cls 1.9405 (2.2268)  triplet 0.0825 (0.0872)  mse 0.0031 (0.0031)  tot 1.9405 (2.2268)  
[Train] Epoch: [1/1][2200/3536]  Time 0.338 (0.750)  cls 2.1427 (2.2124)  triplet 0.1156 (0.0875)  mse 0.0033 (0.0031)  tot 2.1427 (2.2124)  
[Train] Epoch: [1/1][2300/3536]  Time 2.419 (0.753)  cls 1.8901 (2.2018)  triplet 0.0315 (0.0871)  mse 0.0031 (0.0032)  tot 1.8901 (2.2018)  
[Train] Epoch: [1/1][2400/3536]  Time 0.338 (0.757)  cls 2.0494 (2.1909)  triplet 0.2060 (0.0874)  mse 0.0032 (0.0032)  tot 2.0494 (2.1909)  
[Train] Epoch: [1/1][2500/3536]  Time 0.338 (0.761)  cls 1.8733 (2.1793)  triplet 0.0123 (0.0870)  mse 0.0032 (0.0032)  tot 1.8733 (2.1793)  
[Train] Epoch: [1/1][2600/3536]  Time 5.445 (0.764)  cls 1.8044 (2.1696)  triplet 0.1132 (0.0869)  mse 0.0031 (0.0032)  tot 1.8044 (2.1696)  
[Train] Epoch: [1/1][2700/3536]  Time 0.342 (0.765)  cls 1.5103 (2.1588)  triplet 0.0216 (0.0865)  mse 0.0032 (0.0032)  tot 1.5103 (2.1588)  
[Train] Epoch: [1/1][2800/3536]  Time 0.337 (0.767)  cls 1.7281 (2.1507)  triplet 0.0215 (0.0864)  mse 0.0032 (0.0032)  tot 1.7281 (2.1507)  
[Train] Epoch: [1/1][2900/3536]  Time 2.794 (0.769)  cls 1.7022 (2.1415)  triplet 0.1255 (0.0863)  mse 0.0032 (0.0032)  tot 1.7022 (2.1415)  
[Train] Epoch: [1/1][3000/3536]  Time 0.338 (0.769)  cls 1.6470 (2.1339)  triplet 0.1130 (0.0862)  mse 0.0031 (0.0032)  tot 1.6470 (2.1339)  
[Train] Epoch: [1/1][3100/3536]  Time 0.335 (0.770)  cls 1.4546 (2.1259)  triplet 0.0268 (0.0860)  mse 0.0032 (0.0032)  tot 1.4546 (2.1259)  
[Train] Epoch: [1/1][3200/3536]  Time 2.451 (0.773)  cls 2.2447 (2.1192)  triplet 0.0306 (0.0859)  mse 0.0031 (0.0032)  tot 2.2447 (2.1192)  
[Train] Epoch: [1/1][3300/3536]  Time 0.342 (0.773)  cls 1.9886 (2.1118)  triplet 0.1250 (0.0860)  mse 0.0032 (0.0032)  tot 1.9886 (2.1118)  
[Train] Epoch: [1/1][3400/3536]  Time 0.341 (0.774)  cls 2.1572 (2.1055)  triplet 0.1725 (0.0859)  mse 0.0031 (0.0032)  tot 2.1572 (2.1055)  
[Train] Epoch: [1/1][3500/3536]  Time 0.334 (0.775)  cls 1.7626 (2.0972)  triplet 0.1255 (0.0858)  mse 0.0030 (0.0032)  tot 1.7626 (2.0972)  
epoch = [1/1]loss = {'net': 2.0953601499960435, 'acc': 0.5531108597285068}

***Validation***
udcdr == 0
Query:sketch; Gallery:real; Generalized:0
================Parameters Settings=================
Parameters:	Namespace(vptNumTokens=4, text='DCoOp', textNumTokens=1, VL_independent=True, generator_layer=0, domain_specific_trick=False, decouple=False, triplet=False, ln_trick=False, log_name='baseline', disable_first_pre_ln=False, second_init='xavier', first_init='xavier', optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro_SIGIR', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 60
================Baseline Settings=================
visual UDP numbers = 4
text prompt-setup = DCoOp
text UDP numbers= 1
UDPs independent? = True
use triplet loss? = False
generator_layer_num = 0
==================================================
======== Training Parameters ========
text_prompt_learner.ctx
text_encoder.text_projection
visual_udp_generator.prompt_embeddings
visual_encoder.class_embedding
visual_encoder.proj
visual_encoder.prompt_embeddings
tot=125987072, train = 662784
===============================================
================Parameters Settings=================
Parameters:	Namespace(vptNumTokens=4, text='DCoOp', textNumTokens=1, VL_independent=True, generator_layer=0, domain_specific_trick=False, decouple=False, triplet=False, ln_trick=False, log_name='baseline', disable_first_pre_ln=False, second_init='xavier', first_init='xavier', optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro_SIGIR', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 60
================Baseline Settings=================
visual UDP numbers = 4
text prompt-setup = DCoOp
text UDP numbers= 1
UDPs independent? = True
use triplet loss? = False
generator_layer_num = 0
==================================================
======== Training Parameters ========
text_prompt_learner.ctx
text_encoder.text_projection
visual_udp_generator.prompt_embeddings
visual_encoder.class_embedding
visual_encoder.proj
visual_encoder.prompt_embeddings
tot=125987072, train = 662784
===============================================
[Train] Epoch: [1/1][100/3536]  Time 0.338 (0.350)  cls 2.5125 (3.8007)  triplet 0.0765 (0.0925)  mse 0.0033 (0.0029)  tot 2.5125 (3.8007)  
[Train] Epoch: [1/1][200/3536]  Time 0.336 (0.343)  cls 2.8957 (3.2240)  triplet 0.1061 (0.0906)  mse 0.0032 (0.0031)  tot 2.8957 (3.2240)  
[Train] Epoch: [1/1][300/3536]  Time 0.336 (0.341)  cls 2.3768 (2.9674)  triplet 0.1060 (0.0928)  mse 0.0032 (0.0031)  tot 2.3768 (2.9674)  
[Train] Epoch: [1/1][400/3536]  Time 0.335 (0.340)  cls 2.4926 (2.8247)  triplet 0.1168 (0.0931)  mse 0.0032 (0.0031)  tot 2.4926 (2.8247)  
[Train] Epoch: [1/1][500/3536]  Time 0.336 (0.339)  cls 2.1771 (2.7221)  triplet 0.0331 (0.0906)  mse 0.0032 (0.0031)  tot 2.1771 (2.7221)  
[Train] Epoch: [1/1][600/3536]  Time 0.343 (0.339)  cls 2.0667 (2.6456)  triplet 0.0619 (0.0907)  mse 0.0032 (0.0032)  tot 2.0667 (2.6456)  
[Train] Epoch: [1/1][700/3536]  Time 0.341 (0.340)  cls 2.0499 (2.5832)  triplet 0.1297 (0.0908)  mse 0.0031 (0.0032)  tot 2.0499 (2.5832)  
[Train] Epoch: [1/1][800/3536]  Time 0.342 (0.340)  cls 2.1537 (2.5323)  triplet 0.0635 (0.0896)  mse 0.0032 (0.0032)  tot 2.1537 (2.5323)  
[Train] Epoch: [1/1][900/3536]  Time 0.341 (0.340)  cls 2.1944 (2.4845)  triplet 0.0898 (0.0891)  mse 0.0032 (0.0032)  tot 2.1944 (2.4845)  
[Train] Epoch: [1/1][1000/3536]  Time 0.341 (0.341)  cls 2.5204 (2.4499)  triplet 0.1106 (0.0890)  mse 0.0032 (0.0032)  tot 2.5204 (2.4499)  
[Train] Epoch: [1/1][1100/3536]  Time 0.341 (0.341)  cls 1.9816 (2.4146)  triplet 0.0523 (0.0885)  mse 0.0031 (0.0032)  tot 1.9816 (2.4146)  
[Train] Epoch: [1/1][1200/3536]  Time 0.349 (0.341)  cls 2.2876 (2.3862)  triplet 0.1320 (0.0888)  mse 0.0031 (0.0032)  tot 2.2876 (2.3862)  
[Train] Epoch: [1/1][1300/3536]  Time 0.345 (0.341)  cls 2.5632 (2.3638)  triplet 0.1080 (0.0887)  mse 0.0031 (0.0032)  tot 2.5632 (2.3638)  
[Train] Epoch: [1/1][1400/3536]  Time 0.350 (0.342)  cls 2.0427 (2.3409)  triplet 0.0821 (0.0881)  mse 0.0032 (0.0032)  tot 2.0427 (2.3409)  
[Train] Epoch: [1/1][1500/3536]  Time 0.342 (0.342)  cls 2.2671 (2.3221)  triplet 0.0984 (0.0883)  mse 0.0032 (0.0032)  tot 2.2671 (2.3221)  
[Train] Epoch: [1/1][1600/3536]  Time 0.347 (0.342)  cls 1.8048 (2.3016)  triplet 0.1789 (0.0883)  mse 0.0032 (0.0032)  tot 1.8048 (2.3016)  
[Train] Epoch: [1/1][1700/3536]  Time 0.344 (0.342)  cls 2.0421 (2.2858)  triplet 0.0238 (0.0875)  mse 0.0031 (0.0032)  tot 2.0421 (2.2858)  
[Train] Epoch: [1/1][1800/3536]  Time 0.347 (0.342)  cls 1.7526 (2.2689)  triplet 0.1230 (0.0873)  mse 0.0032 (0.0032)  tot 1.7526 (2.2689)  
[Train] Epoch: [1/1][1900/3536]  Time 0.349 (0.342)  cls 1.7075 (2.2537)  triplet 0.0284 (0.0874)  mse 0.0030 (0.0032)  tot 1.7075 (2.2537)  
[Train] Epoch: [1/1][2000/3536]  Time 0.355 (0.343)  cls 1.8247 (2.2404)  triplet 0.0696 (0.0872)  mse 0.0031 (0.0032)  tot 1.8247 (2.2404)  
[Train] Epoch: [1/1][2100/3536]  Time 0.344 (0.343)  cls 1.9405 (2.2268)  triplet 0.0825 (0.0872)  mse 0.0031 (0.0031)  tot 1.9405 (2.2268)  
[Train] Epoch: [1/1][2200/3536]  Time 0.342 (0.343)  cls 2.1427 (2.2124)  triplet 0.1156 (0.0875)  mse 0.0033 (0.0031)  tot 2.1427 (2.2124)  
[Train] Epoch: [1/1][2300/3536]  Time 0.344 (0.343)  cls 1.8901 (2.2018)  triplet 0.0315 (0.0871)  mse 0.0031 (0.0032)  tot 1.8901 (2.2018)  
[Train] Epoch: [1/1][2400/3536]  Time 0.348 (0.343)  cls 2.0494 (2.1909)  triplet 0.2060 (0.0874)  mse 0.0032 (0.0032)  tot 2.0494 (2.1909)  
[Train] Epoch: [1/1][2500/3536]  Time 0.342 (0.343)  cls 1.8733 (2.1793)  triplet 0.0123 (0.0870)  mse 0.0032 (0.0032)  tot 1.8733 (2.1793)  
[Train] Epoch: [1/1][2600/3536]  Time 0.342 (0.343)  cls 1.8044 (2.1696)  triplet 0.1132 (0.0869)  mse 0.0031 (0.0032)  tot 1.8044 (2.1696)  
[Train] Epoch: [1/1][2700/3536]  Time 0.354 (0.343)  cls 1.5103 (2.1588)  triplet 0.0216 (0.0865)  mse 0.0032 (0.0032)  tot 1.5103 (2.1588)  
[Train] Epoch: [1/1][2800/3536]  Time 0.345 (0.343)  cls 1.7281 (2.1507)  triplet 0.0215 (0.0864)  mse 0.0032 (0.0032)  tot 1.7281 (2.1507)  
[Train] Epoch: [1/1][2900/3536]  Time 0.344 (0.343)  cls 1.7022 (2.1415)  triplet 0.1255 (0.0863)  mse 0.0032 (0.0032)  tot 1.7022 (2.1415)  
[Train] Epoch: [1/1][3000/3536]  Time 0.341 (0.343)  cls 1.6470 (2.1339)  triplet 0.1130 (0.0862)  mse 0.0031 (0.0032)  tot 1.6470 (2.1339)  
[Train] Epoch: [1/1][3100/3536]  Time 0.352 (0.344)  cls 1.4546 (2.1259)  triplet 0.0268 (0.0860)  mse 0.0032 (0.0032)  tot 1.4546 (2.1259)  
[Train] Epoch: [1/1][3200/3536]  Time 0.347 (0.344)  cls 2.2447 (2.1192)  triplet 0.0306 (0.0859)  mse 0.0031 (0.0032)  tot 2.2447 (2.1192)  
[Train] Epoch: [1/1][3300/3536]  Time 0.348 (0.344)  cls 1.9886 (2.1118)  triplet 0.1250 (0.0860)  mse 0.0032 (0.0032)  tot 1.9886 (2.1118)  
[Train] Epoch: [1/1][3400/3536]  Time 0.349 (0.344)  cls 2.1572 (2.1055)  triplet 0.1725 (0.0859)  mse 0.0031 (0.0032)  tot 2.1572 (2.1055)  
[Train] Epoch: [1/1][3500/3536]  Time 0.346 (0.344)  cls 1.7626 (2.0972)  triplet 0.1255 (0.0858)  mse 0.0030 (0.0032)  tot 1.7626 (2.0972)  
epoch = [1/1]loss = {'net': 2.0953601499960435, 'acc': 0.5531108597285068}

***Validation***
udcdr == 0
Query:sketch; Gallery:real; Generalized:0

Query Emb Dim:torch.Size([9729, 512]); Gallery Emb Dim:torch.Size([24387, 512])
computing unormed situation
tensor(0.6094, device='cuda:1') tensor(0.5591, device='cuda:1')
tensor(0.2799, device='cuda:1') tensor(0.2047, device='cuda:1')
tensor(0.5951, device='cuda:1') tensor(0.5416, device='cuda:1')
computing normed situation
tensor(0.6484, device='cuda:1') tensor(0.6053, device='cuda:1')
tensor(0.2763, device='cuda:1') tensor(0.2028, device='cuda:1')
tensor(0.6407, device='cuda:1') tensor(0.5956, device='cuda:1')
un-norm situation:
learned: map: 0.6093537211418152, prec: 0.559149980545044
11fixed: map: 0.27985119819641113, prec: 0.20467263460159302
combine: map: 0.5950842499732971, prec: 0.5416327714920044
norm situation:
learned: map: 0.6483510136604309, prec: 0.6052775382995605
11fixed: map: 0.2762945294380188, prec: 0.2028019279241562
combine: map: 0.6406680345535278, prec: 0.595635712146759
Query:sketch; Gallery:real; Generalized:1

Query Emb Dim:torch.Size([9729, 512]); Gallery Emb Dim:torch.Size([36600, 512])
computing unormed situation
tensor(0.5555, device='cuda:1') tensor(0.5087, device='cuda:1')
tensor(0.2380, device='cuda:1') tensor(0.1685, device='cuda:1')
tensor(0.5408, device='cuda:1') tensor(0.4907, device='cuda:1')
computing normed situation
tensor(0.5761, device='cuda:1') tensor(0.5402, device='cuda:1')
tensor(0.2333, device='cuda:1') tensor(0.1660, device='cuda:1')
tensor(0.5696, device='cuda:1') tensor(0.5311, device='cuda:1')
un-norm situation:
learned: map: 0.5554757714271545, prec: 0.5087172389030457
11fixed: map: 0.23802004754543304, prec: 0.1685430109500885
combine: map: 0.5407610535621643, prec: 0.4906536936759949
norm situation:
learned: map: 0.5761433243751526, prec: 0.5402487516403198
11fixed: map: 0.2333245724439621, prec: 0.1660463511943817
combine: map: 0.5695950984954834, prec: 0.5310720205307007
udcdr == 1

Query Emb Dim:torch.Size([1883, 512]); Gallery Emb Dim:torch.Size([5857, 512])
computing unormed situation
tensor(0.6954, device='cuda:1') tensor(0.4673, device='cuda:1')
tensor(0.3599, device='cuda:1') tensor(0.2004, device='cuda:1')
tensor(0.6836, device='cuda:1') tensor(0.4585, device='cuda:1')
computing normed situation
tensor(0.7494, device='cuda:1') tensor(0.4994, device='cuda:1')
tensor(0.3608, device='cuda:1') tensor(0.2014, device='cuda:1')
tensor(0.7422, device='cuda:1') tensor(0.4948, device='cuda:1')
un-norm situation:
learned: map: 0.6953539848327637, prec: 0.4673234224319458
11fixed: map: 0.35993820428848267, prec: 0.20041422545909882
combine: map: 0.6835978627204895, prec: 0.45852893590927124
norm situation:
learned: map: 0.7493734955787659, prec: 0.4994317293167114
11fixed: map: 0.360826700925827, prec: 0.2014153003692627
combine: map: 0.7422180771827698, prec: 0.4947955310344696
Epoch Time:29m56s lr:0.0001000 mAP:0.5696 prec:0.5311

Error: /home/user/Code/DePro_SIGIR/src/algos/depro/log/DomainNet/seen-quickdraw_unseen-sketch_x_real/init.pth file not found

***Training and Validation complete***
