================Parameters Settings=================
Parameters:	Namespace(vptNumTokens=4, text='DCoOp', textNumTokens=1, VL_independent=True, generator_layer=2, domain_specific_trick=False, decouple=True, triplet=False, ln_trick=True, log_name='depro_ln_trick', disable_first_pre_ln=False, second_init='xavier', first_init='xavier', optimizer='adam', l2_reg=0.0, epochs=1, lr=0.0001, momentum=0.9, resume_dict=None, code_path='/home/user/Code/DePro_SIGIR', dataset_path='/data/UCDR/data', dataset='DomainNet', is_eccv_split=1, clip_backbone='ViT-B/32', CLS_NUM_TOKENS=300, DOM_NUM_TOKENS=5, debug_mode=0, dropout=0.5, seen_domain='quickdraw', holdout_domain='sketch', gallery_domain='real', include_auxillary_domains=1, udcdr=0, image_size=224, seed=0, batch_size=60, num_workers=6, early_stop=2, log_interval=100)
================Training Settings=================
lr = 0.0001
batch_size = 60
================Universal Domain Prompts Settings=================
visual UDP number = 4
text prompt-setup = DCoOp
text UDP number= 1
UDPs independent? = True
================ Class Prompts Settings=================
Meta-Net Used? = True
Meta-Net layer depth = 2
================ Decouple loss Settings=================
Decouple Used? = True
================ Trick Settings=================
LN Trick used? = True
vit out_order = 0
use triplet loss? = False
generator_layer_num = 2
==================================================
======== Training Parameters ========
text_prompt_learner.ctx
text_encoder.text_projection
ln:  text_encoder.transformer.resblocks.0.ln_1.weight
ln:  text_encoder.transformer.resblocks.0.ln_1.bias
ln:  text_encoder.transformer.resblocks.0.ln_2.weight
ln:  text_encoder.transformer.resblocks.0.ln_2.bias
ln:  text_encoder.transformer.resblocks.1.ln_1.weight
ln:  text_encoder.transformer.resblocks.1.ln_1.bias
ln:  text_encoder.transformer.resblocks.1.ln_2.weight
ln:  text_encoder.transformer.resblocks.1.ln_2.bias
ln:  text_encoder.transformer.resblocks.2.ln_1.weight
ln:  text_encoder.transformer.resblocks.2.ln_1.bias
ln:  text_encoder.transformer.resblocks.2.ln_2.weight
ln:  text_encoder.transformer.resblocks.2.ln_2.bias
ln:  text_encoder.transformer.resblocks.3.ln_1.weight
ln:  text_encoder.transformer.resblocks.3.ln_1.bias
ln:  text_encoder.transformer.resblocks.3.ln_2.weight
ln:  text_encoder.transformer.resblocks.3.ln_2.bias
ln:  text_encoder.transformer.resblocks.4.ln_1.weight
ln:  text_encoder.transformer.resblocks.4.ln_1.bias
ln:  text_encoder.transformer.resblocks.4.ln_2.weight
ln:  text_encoder.transformer.resblocks.4.ln_2.bias
ln:  text_encoder.transformer.resblocks.5.ln_1.weight
ln:  text_encoder.transformer.resblocks.5.ln_1.bias
ln:  text_encoder.transformer.resblocks.5.ln_2.weight
ln:  text_encoder.transformer.resblocks.5.ln_2.bias
ln:  text_encoder.transformer.resblocks.6.ln_1.weight
ln:  text_encoder.transformer.resblocks.6.ln_1.bias
ln:  text_encoder.transformer.resblocks.6.ln_2.weight
ln:  text_encoder.transformer.resblocks.6.ln_2.bias
ln:  text_encoder.transformer.resblocks.7.ln_1.weight
ln:  text_encoder.transformer.resblocks.7.ln_1.bias
ln:  text_encoder.transformer.resblocks.7.ln_2.weight
ln:  text_encoder.transformer.resblocks.7.ln_2.bias
ln:  text_encoder.transformer.resblocks.8.ln_1.weight
ln:  text_encoder.transformer.resblocks.8.ln_1.bias
ln:  text_encoder.transformer.resblocks.8.ln_2.weight
ln:  text_encoder.transformer.resblocks.8.ln_2.bias
ln:  text_encoder.transformer.resblocks.9.ln_1.weight
ln:  text_encoder.transformer.resblocks.9.ln_1.bias
ln:  text_encoder.transformer.resblocks.9.ln_2.weight
ln:  text_encoder.transformer.resblocks.9.ln_2.bias
ln:  text_encoder.transformer.resblocks.10.ln_1.weight
ln:  text_encoder.transformer.resblocks.10.ln_1.bias
ln:  text_encoder.transformer.resblocks.10.ln_2.weight
ln:  text_encoder.transformer.resblocks.10.ln_2.bias
ln:  text_encoder.transformer.resblocks.11.ln_1.weight
ln:  text_encoder.transformer.resblocks.11.ln_1.bias
ln:  text_encoder.transformer.resblocks.11.ln_2.weight
ln:  text_encoder.transformer.resblocks.11.ln_2.bias
ln:  text_encoder.ln_final.weight
ln:  text_encoder.ln_final.bias
visual_udp_generator.prompt_embeddings
visual_encoder.class_embedding
visual_encoder.proj
visual_encoder.prompt_embeddings
ln:  visual_encoder.ln_pre.weight
ln:  visual_encoder.ln_pre.bias
ln:  visual_encoder.transformer.resblocks.0.ln_1.weight
ln:  visual_encoder.transformer.resblocks.0.ln_1.bias
ln:  visual_encoder.transformer.resblocks.0.ln_2.weight
ln:  visual_encoder.transformer.resblocks.0.ln_2.bias
ln:  visual_encoder.transformer.resblocks.1.ln_1.weight
ln:  visual_encoder.transformer.resblocks.1.ln_1.bias
ln:  visual_encoder.transformer.resblocks.1.ln_2.weight
ln:  visual_encoder.transformer.resblocks.1.ln_2.bias
ln:  visual_encoder.transformer.resblocks.2.ln_1.weight
ln:  visual_encoder.transformer.resblocks.2.ln_1.bias
ln:  visual_encoder.transformer.resblocks.2.ln_2.weight
ln:  visual_encoder.transformer.resblocks.2.ln_2.bias
ln:  visual_encoder.transformer.resblocks.3.ln_1.weight
ln:  visual_encoder.transformer.resblocks.3.ln_1.bias
ln:  visual_encoder.transformer.resblocks.3.ln_2.weight
ln:  visual_encoder.transformer.resblocks.3.ln_2.bias
ln:  visual_encoder.transformer.resblocks.4.ln_1.weight
ln:  visual_encoder.transformer.resblocks.4.ln_1.bias
ln:  visual_encoder.transformer.resblocks.4.ln_2.weight
ln:  visual_encoder.transformer.resblocks.4.ln_2.bias
ln:  visual_encoder.transformer.resblocks.5.ln_1.weight
ln:  visual_encoder.transformer.resblocks.5.ln_1.bias
ln:  visual_encoder.transformer.resblocks.5.ln_2.weight
ln:  visual_encoder.transformer.resblocks.5.ln_2.bias
ln:  visual_encoder.transformer.resblocks.6.ln_1.weight
ln:  visual_encoder.transformer.resblocks.6.ln_1.bias
ln:  visual_encoder.transformer.resblocks.6.ln_2.weight
ln:  visual_encoder.transformer.resblocks.6.ln_2.bias
ln:  visual_encoder.transformer.resblocks.7.ln_1.weight
ln:  visual_encoder.transformer.resblocks.7.ln_1.bias
ln:  visual_encoder.transformer.resblocks.7.ln_2.weight
ln:  visual_encoder.transformer.resblocks.7.ln_2.bias
ln:  visual_encoder.transformer.resblocks.8.ln_1.weight
ln:  visual_encoder.transformer.resblocks.8.ln_1.bias
ln:  visual_encoder.transformer.resblocks.8.ln_2.weight
ln:  visual_encoder.transformer.resblocks.8.ln_2.bias
ln:  visual_encoder.transformer.resblocks.9.ln_1.weight
ln:  visual_encoder.transformer.resblocks.9.ln_1.bias
ln:  visual_encoder.transformer.resblocks.9.ln_2.weight
ln:  visual_encoder.transformer.resblocks.9.ln_2.bias
ln:  visual_encoder.transformer.resblocks.10.ln_1.weight
ln:  visual_encoder.transformer.resblocks.10.ln_1.bias
ln:  visual_encoder.transformer.resblocks.10.ln_2.weight
ln:  visual_encoder.transformer.resblocks.10.ln_2.bias
ln:  visual_encoder.transformer.resblocks.11.ln_1.weight
ln:  visual_encoder.transformer.resblocks.11.ln_1.bias
ln:  visual_encoder.transformer.resblocks.11.ln_2.weight
ln:  visual_encoder.transformer.resblocks.11.ln_2.bias
ln:  visual_encoder.ln_post.weight
ln:  visual_encoder.ln_post.bias
visual_encoder.meta_net.proj
visual_encoder.meta_net.specific_domain_prompts
visual_encoder.meta_net.specific_class_prompts
visual_encoder.meta_net.vit.class_embedding
visual_encoder.meta_net.vit.positional_embedding
visual_encoder.meta_net.vit.proj
visual_encoder.meta_net.vit.conv1.weight
ln:  visual_encoder.meta_net.vit.ln_pre.weight
ln:  visual_encoder.meta_net.vit.ln_pre.bias
visual_encoder.meta_net.vit.transformer.resblocks.0.attn.in_proj_weight
visual_encoder.meta_net.vit.transformer.resblocks.0.attn.in_proj_bias
visual_encoder.meta_net.vit.transformer.resblocks.0.attn.out_proj.weight
visual_encoder.meta_net.vit.transformer.resblocks.0.attn.out_proj.bias
ln:  visual_encoder.meta_net.vit.transformer.resblocks.0.ln_1.weight
ln:  visual_encoder.meta_net.vit.transformer.resblocks.0.ln_1.bias
visual_encoder.meta_net.vit.transformer.resblocks.0.mlp.c_fc.weight
visual_encoder.meta_net.vit.transformer.resblocks.0.mlp.c_fc.bias
visual_encoder.meta_net.vit.transformer.resblocks.0.mlp.c_proj.weight
visual_encoder.meta_net.vit.transformer.resblocks.0.mlp.c_proj.bias
ln:  visual_encoder.meta_net.vit.transformer.resblocks.0.ln_2.weight
ln:  visual_encoder.meta_net.vit.transformer.resblocks.0.ln_2.bias
visual_encoder.meta_net.vit.transformer.resblocks.1.attn.in_proj_weight
visual_encoder.meta_net.vit.transformer.resblocks.1.attn.in_proj_bias
visual_encoder.meta_net.vit.transformer.resblocks.1.attn.out_proj.weight
visual_encoder.meta_net.vit.transformer.resblocks.1.attn.out_proj.bias
ln:  visual_encoder.meta_net.vit.transformer.resblocks.1.ln_1.weight
ln:  visual_encoder.meta_net.vit.transformer.resblocks.1.ln_1.bias
visual_encoder.meta_net.vit.transformer.resblocks.1.mlp.c_fc.weight
visual_encoder.meta_net.vit.transformer.resblocks.1.mlp.c_fc.bias
visual_encoder.meta_net.vit.transformer.resblocks.1.mlp.c_proj.weight
visual_encoder.meta_net.vit.transformer.resblocks.1.mlp.c_proj.bias
ln:  visual_encoder.meta_net.vit.transformer.resblocks.1.ln_2.weight
ln:  visual_encoder.meta_net.vit.transformer.resblocks.1.ln_2.bias
ln:  visual_encoder.meta_net.vit.ln_post.weight
ln:  visual_encoder.meta_net.vit.ln_post.bias
tot=143781632, train = 18522880
===============================================
[Train] Epoch: [1/1][100/3536]  Time 0.396 (0.411)  cls 5.6834 (6.9299)  triplet 0.1357 (0.1765)  mse 0.0001 (0.0001)  tot 5.6834 (6.9299)  
[Train] Epoch: [1/1][200/3536]  Time 0.397 (0.403)  cls 6.0042 (6.3582)  triplet 0.1841 (0.1720)  mse 0.0000 (0.0001)  tot 6.0042 (6.3582)  
[Train] Epoch: [1/1][300/3536]  Time 0.397 (0.401)  cls 5.0989 (6.0683)  triplet 0.1922 (0.1769)  mse 0.0000 (0.0001)  tot 5.0989 (6.0683)  
[Train] Epoch: [1/1][400/3536]  Time 0.396 (0.400)  cls 5.4719 (5.8887)  triplet 0.2570 (0.1786)  mse 0.0000 (0.0001)  tot 5.4719 (5.8887)  
[Train] Epoch: [1/1][500/3536]  Time 0.399 (0.399)  cls 4.9647 (5.7580)  triplet 0.0550 (0.1728)  mse 0.0000 (0.0001)  tot 4.9647 (5.7580)  
[Train] Epoch: [1/1][600/3536]  Time 0.396 (0.399)  cls 4.9931 (5.6639)  triplet 0.1070 (0.1737)  mse 0.0000 (0.0000)  tot 4.9931 (5.6639)  
[Train] Epoch: [1/1][700/3536]  Time 0.395 (0.399)  cls 4.5541 (5.5789)  triplet 0.2137 (0.1739)  mse 0.0000 (0.0000)  tot 4.5541 (5.5789)  
[Train] Epoch: [1/1][800/3536]  Time 0.397 (0.398)  cls 5.4454 (5.5077)  triplet 0.1178 (0.1715)  mse 0.0000 (0.0000)  tot 5.4454 (5.5077)  
[Train] Epoch: [1/1][900/3536]  Time 0.397 (0.398)  cls 4.9480 (5.4387)  triplet 0.1791 (0.1707)  mse 0.0000 (0.0000)  tot 4.9480 (5.4387)  
[Train] Epoch: [1/1][1000/3536]  Time 0.395 (0.398)  cls 5.4405 (5.3839)  triplet 0.2304 (0.1708)  mse 0.0000 (0.0000)  tot 5.4405 (5.3839)  
[Train] Epoch: [1/1][1100/3536]  Time 0.397 (0.398)  cls 4.4209 (5.3293)  triplet 0.1162 (0.1700)  mse 0.0000 (0.0000)  tot 4.4209 (5.3293)  
[Train] Epoch: [1/1][1200/3536]  Time 0.397 (0.398)  cls 5.1532 (5.2879)  triplet 0.2381 (0.1709)  mse 0.0000 (0.0000)  tot 5.1532 (5.2879)  
[Train] Epoch: [1/1][1300/3536]  Time 0.398 (0.398)  cls 6.0829 (5.2511)  triplet 0.2215 (0.1707)  mse 0.0000 (0.0000)  tot 6.0829 (5.2511)  
[Train] Epoch: [1/1][1400/3536]  Time 0.427 (0.398)  cls 4.6908 (5.2144)  triplet 0.1666 (0.1694)  mse 0.0000 (0.0000)  tot 4.6908 (5.2144)  
[Train] Epoch: [1/1][1500/3536]  Time 0.402 (0.398)  cls 4.9745 (5.1802)  triplet 0.1895 (0.1699)  mse 0.0000 (0.0000)  tot 4.9745 (5.1802)  
[Train] Epoch: [1/1][1600/3536]  Time 0.404 (0.399)  cls 4.3811 (5.1468)  triplet 0.3645 (0.1700)  mse 0.0000 (0.0000)  tot 4.3811 (5.1468)  
[Train] Epoch: [1/1][1700/3536]  Time 0.409 (0.399)  cls 4.8503 (5.1189)  triplet 0.0364 (0.1684)  mse 0.0000 (0.0000)  tot 4.8503 (5.1189)  
[Train] Epoch: [1/1][1800/3536]  Time 0.404 (0.400)  cls 3.9632 (5.0897)  triplet 0.2066 (0.1677)  mse 0.0000 (0.0000)  tot 3.9632 (5.0897)  
[Train] Epoch: [1/1][1900/3536]  Time 0.408 (0.400)  cls 4.2590 (5.0628)  triplet 0.0680 (0.1680)  mse 0.0000 (0.0000)  tot 4.2590 (5.0628)  
[Train] Epoch: [1/1][2000/3536]  Time 0.406 (0.400)  cls 4.5643 (5.0423)  triplet 0.1490 (0.1676)  mse 0.0000 (0.0000)  tot 4.5643 (5.0423)  
[Train] Epoch: [1/1][2100/3536]  Time 0.404 (0.401)  cls 4.5495 (5.0182)  triplet 0.1750 (0.1676)  mse 0.0000 (0.0000)  tot 4.5495 (5.0182)  
[Train] Epoch: [1/1][2200/3536]  Time 0.407 (0.401)  cls 4.8731 (4.9962)  triplet 0.2182 (0.1680)  mse 0.0000 (0.0000)  tot 4.8731 (4.9962)  
[Train] Epoch: [1/1][2300/3536]  Time 0.403 (0.401)  cls 4.4407 (4.9788)  triplet 0.0693 (0.1672)  mse 0.0000 (0.0000)  tot 4.4407 (4.9788)  
[Train] Epoch: [1/1][2400/3536]  Time 0.407 (0.401)  cls 4.9362 (4.9593)  triplet 0.4072 (0.1676)  mse 0.0001 (0.0000)  tot 4.9362 (4.9593)  
[Train] Epoch: [1/1][2500/3536]  Time 0.410 (0.401)  cls 4.8533 (4.9406)  triplet 0.0210 (0.1668)  mse 0.0000 (0.0000)  tot 4.8533 (4.9406)  
[Train] Epoch: [1/1][2600/3536]  Time 0.411 (0.402)  cls 4.1320 (4.9235)  triplet 0.2062 (0.1667)  mse 0.0001 (0.0000)  tot 4.1320 (4.9235)  
[Train] Epoch: [1/1][2700/3536]  Time 0.411 (0.402)  cls 3.6814 (4.9040)  triplet 0.0346 (0.1659)  mse 0.0001 (0.0000)  tot 3.6814 (4.9040)  
[Train] Epoch: [1/1][2800/3536]  Time 0.405 (0.402)  cls 4.0820 (4.8908)  triplet 0.0268 (0.1660)  mse 0.0001 (0.0000)  tot 4.0820 (4.8908)  
[Train] Epoch: [1/1][2900/3536]  Time 0.410 (0.402)  cls 4.1448 (4.8746)  triplet 0.2428 (0.1657)  mse 0.0001 (0.0000)  tot 4.1448 (4.8746)  
[Train] Epoch: [1/1][3000/3536]  Time 0.408 (0.402)  cls 3.9568 (4.8613)  triplet 0.2179 (0.1654)  mse 0.0001 (0.0000)  tot 3.9568 (4.8613)  
[Train] Epoch: [1/1][3100/3536]  Time 0.406 (0.402)  cls 3.5857 (4.8474)  triplet 0.0536 (0.1650)  mse 0.0001 (0.0000)  tot 3.5857 (4.8474)  
[Train] Epoch: [1/1][3200/3536]  Time 0.405 (0.403)  cls 5.0047 (4.8352)  triplet 0.0415 (0.1649)  mse 0.0001 (0.0000)  tot 5.0047 (4.8352)  
[Train] Epoch: [1/1][3300/3536]  Time 0.407 (0.403)  cls 4.3288 (4.8213)  triplet 0.1993 (0.1650)  mse 0.0001 (0.0000)  tot 4.3288 (4.8213)  
[Train] Epoch: [1/1][3400/3536]  Time 0.409 (0.403)  cls 4.5810 (4.8098)  triplet 0.3618 (0.1650)  mse 0.0001 (0.0000)  tot 4.5810 (4.8098)  
[Train] Epoch: [1/1][3500/3536]  Time 0.413 (0.403)  cls 4.3467 (4.7946)  triplet 0.2032 (0.1646)  mse 0.0001 (0.0000)  tot 4.3467 (4.7946)  
epoch = [1/1]loss = {'net': 4.790952029069085, 'acc': 0.582979826546003}

***Validation***
udcdr == 0
Query:sketch; Gallery:real; Generalized:0

Query Emb Dim:torch.Size([9729, 512]); Gallery Emb Dim:torch.Size([24387, 512])
computing unormed situation
tensor(0.6635, device='cuda:1') tensor(0.6166, device='cuda:1')
tensor(0.6589, device='cuda:1') tensor(0.6135, device='cuda:1')
tensor(0.6629, device='cuda:1') tensor(0.6171, device='cuda:1')
computing normed situation
tensor(0.6721, device='cuda:1') tensor(0.6296, device='cuda:1')
tensor(0.6750, device='cuda:1') tensor(0.6341, device='cuda:1')
tensor(0.6746, device='cuda:1') tensor(0.6329, device='cuda:1')
un-norm situation:
learned: map: 0.6635158658027649, prec: 0.6165968179702759
11fixed: map: 0.658886730670929, prec: 0.6134587526321411
combine: map: 0.6629257202148438, prec: 0.6170561909675598
norm situation:
learned: map: 0.6720777153968811, prec: 0.6295514106750488
11fixed: map: 0.6750087141990662, prec: 0.634101152420044
combine: map: 0.6745896935462952, prec: 0.632901132106781
Query:sketch; Gallery:real; Generalized:1

Query Emb Dim:torch.Size([9729, 512]); Gallery Emb Dim:torch.Size([36600, 512])
computing unormed situation
tensor(0.6066, device='cuda:1') tensor(0.5678, device='cuda:1')
tensor(0.6023, device='cuda:1') tensor(0.5647, device='cuda:1')
tensor(0.6061, device='cuda:1') tensor(0.5682, device='cuda:1')
computing normed situation
tensor(0.5949, device='cuda:1') tensor(0.5619, device='cuda:1')
tensor(0.5981, device='cuda:1') tensor(0.5661, device='cuda:1')
tensor(0.5976, device='cuda:1') tensor(0.5651, device='cuda:1')
un-norm situation:
learned: map: 0.6066123247146606, prec: 0.5678065419197083
11fixed: map: 0.6023157238960266, prec: 0.564689576625824
combine: map: 0.6060943007469177, prec: 0.5682079195976257
norm situation:
learned: map: 0.5949252247810364, prec: 0.5618732571601868
11fixed: map: 0.5981494188308716, prec: 0.5660607814788818
combine: map: 0.5976012349128723, prec: 0.5650689005851746
udcdr == 1

Query Emb Dim:torch.Size([1883, 512]); Gallery Emb Dim:torch.Size([5857, 512])
computing unormed situation
tensor(0.7580, device='cuda:1') tensor(0.5085, device='cuda:1')
tensor(0.7608, device='cuda:1') tensor(0.5129, device='cuda:1')
tensor(0.7604, device='cuda:1') tensor(0.5117, device='cuda:1')
computing normed situation
tensor(0.7864, device='cuda:1') tensor(0.5218, device='cuda:1')
tensor(0.7887, device='cuda:1') tensor(0.5249, device='cuda:1')
tensor(0.7884, device='cuda:1') tensor(0.5240, device='cuda:1')
un-norm situation:
learned: map: 0.7580153346061707, prec: 0.5085235834121704
11fixed: map: 0.7608186602592468, prec: 0.5129155516624451
combine: map: 0.7604168653488159, prec: 0.5117153525352478
norm situation:
learned: map: 0.7864248156547546, prec: 0.5218268632888794
11fixed: map: 0.788716733455658, prec: 0.5248964428901672
combine: map: 0.7884363532066345, prec: 0.5240440964698792
Epoch Time:31m29s lr:0.0001000 mAP:0.5976 prec:0.5651

Error: /home/user/Code/DePro_SIGIR/src/algos/depro/log/DomainNet/seen-quickdraw_unseen-sketch_x_real/init.pth file not found

***Training and Validation complete***
